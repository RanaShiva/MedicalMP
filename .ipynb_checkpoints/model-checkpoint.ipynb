{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa937413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-class classification with Keras\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3ebbd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataframe = pandas.read_csv(\"dataDisease/Training.csv\", header=0)\n",
    "dataset = dataframe.values\n",
    "X = dataset[:, 0:132].astype(int)\n",
    "Y = dataset[:, 132]\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "247a9640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "886/886 - 1s - loss: 2.4970 - accuracy: 0.4982 - 872ms/epoch - 984us/step\n",
      "Epoch 2/50\n",
      "886/886 - 1s - loss: 0.5647 - accuracy: 0.9855 - 548ms/epoch - 618us/step\n",
      "Epoch 3/50\n",
      "886/886 - 1s - loss: 0.1444 - accuracy: 1.0000 - 554ms/epoch - 625us/step\n",
      "Epoch 4/50\n",
      "886/886 - 1s - loss: 0.0541 - accuracy: 1.0000 - 546ms/epoch - 616us/step\n",
      "Epoch 5/50\n",
      "886/886 - 1s - loss: 0.0255 - accuracy: 1.0000 - 550ms/epoch - 621us/step\n",
      "Epoch 6/50\n",
      "886/886 - 1s - loss: 0.0136 - accuracy: 1.0000 - 535ms/epoch - 604us/step\n",
      "Epoch 7/50\n",
      "886/886 - 1s - loss: 0.0078 - accuracy: 1.0000 - 550ms/epoch - 621us/step\n",
      "Epoch 8/50\n",
      "886/886 - 1s - loss: 0.0047 - accuracy: 1.0000 - 536ms/epoch - 605us/step\n",
      "Epoch 9/50\n",
      "886/886 - 1s - loss: 0.0029 - accuracy: 1.0000 - 545ms/epoch - 615us/step\n",
      "Epoch 10/50\n",
      "886/886 - 1s - loss: 0.0018 - accuracy: 1.0000 - 541ms/epoch - 611us/step\n",
      "Epoch 11/50\n",
      "886/886 - 1s - loss: 0.0011 - accuracy: 1.0000 - 549ms/epoch - 620us/step\n",
      "Epoch 12/50\n",
      "886/886 - 1s - loss: 7.4510e-04 - accuracy: 1.0000 - 547ms/epoch - 617us/step\n",
      "Epoch 13/50\n",
      "886/886 - 1s - loss: 4.7230e-04 - accuracy: 1.0000 - 535ms/epoch - 604us/step\n",
      "Epoch 14/50\n",
      "886/886 - 1s - loss: 3.1511e-04 - accuracy: 1.0000 - 543ms/epoch - 613us/step\n",
      "Epoch 15/50\n",
      "886/886 - 1s - loss: 2.0859e-04 - accuracy: 1.0000 - 554ms/epoch - 625us/step\n",
      "Epoch 16/50\n",
      "886/886 - 1s - loss: 1.3596e-04 - accuracy: 1.0000 - 562ms/epoch - 635us/step\n",
      "Epoch 17/50\n",
      "886/886 - 1s - loss: 9.0132e-05 - accuracy: 1.0000 - 566ms/epoch - 639us/step\n",
      "Epoch 18/50\n",
      "886/886 - 1s - loss: 6.0177e-05 - accuracy: 1.0000 - 554ms/epoch - 625us/step\n",
      "Epoch 19/50\n",
      "886/886 - 1s - loss: 3.9314e-05 - accuracy: 1.0000 - 549ms/epoch - 620us/step\n",
      "Epoch 20/50\n",
      "886/886 - 1s - loss: 2.6945e-05 - accuracy: 1.0000 - 557ms/epoch - 629us/step\n",
      "Epoch 21/50\n",
      "886/886 - 1s - loss: 1.7896e-05 - accuracy: 1.0000 - 551ms/epoch - 622us/step\n",
      "Epoch 22/50\n",
      "886/886 - 1s - loss: 1.2069e-05 - accuracy: 1.0000 - 550ms/epoch - 621us/step\n",
      "Epoch 23/50\n",
      "886/886 - 1s - loss: 8.0497e-06 - accuracy: 1.0000 - 544ms/epoch - 615us/step\n",
      "Epoch 24/50\n",
      "886/886 - 1s - loss: 5.6093e-06 - accuracy: 1.0000 - 550ms/epoch - 621us/step\n",
      "Epoch 25/50\n",
      "886/886 - 1s - loss: 3.8233e-06 - accuracy: 1.0000 - 550ms/epoch - 621us/step\n",
      "Epoch 26/50\n",
      "886/886 - 1s - loss: 2.5949e-06 - accuracy: 1.0000 - 560ms/epoch - 632us/step\n",
      "Epoch 27/50\n",
      "886/886 - 1s - loss: 1.7256e-06 - accuracy: 1.0000 - 552ms/epoch - 623us/step\n",
      "Epoch 28/50\n",
      "886/886 - 1s - loss: 1.2125e-06 - accuracy: 1.0000 - 554ms/epoch - 625us/step\n",
      "Epoch 29/50\n",
      "886/886 - 1s - loss: 8.5083e-07 - accuracy: 1.0000 - 547ms/epoch - 617us/step\n",
      "Epoch 30/50\n",
      "886/886 - 1s - loss: 5.4811e-07 - accuracy: 1.0000 - 560ms/epoch - 632us/step\n",
      "Epoch 31/50\n",
      "886/886 - 1s - loss: 4.2643e-07 - accuracy: 1.0000 - 552ms/epoch - 623us/step\n",
      "Epoch 32/50\n",
      "886/886 - 1s - loss: 2.8728e-07 - accuracy: 1.0000 - 546ms/epoch - 617us/step\n",
      "Epoch 33/50\n",
      "886/886 - 1s - loss: 2.1063e-07 - accuracy: 1.0000 - 555ms/epoch - 626us/step\n",
      "Epoch 34/50\n",
      "886/886 - 1s - loss: 1.5973e-07 - accuracy: 1.0000 - 568ms/epoch - 641us/step\n",
      "Epoch 35/50\n",
      "886/886 - 1s - loss: 1.2096e-07 - accuracy: 1.0000 - 551ms/epoch - 621us/step\n",
      "Epoch 36/50\n",
      "886/886 - 1s - loss: 7.8907e-08 - accuracy: 1.0000 - 552ms/epoch - 624us/step\n",
      "Epoch 37/50\n",
      "886/886 - 1s - loss: 6.0493e-08 - accuracy: 1.0000 - 556ms/epoch - 627us/step\n",
      "Epoch 38/50\n",
      "886/886 - 1s - loss: 4.8513e-08 - accuracy: 1.0000 - 561ms/epoch - 633us/step\n",
      "Epoch 39/50\n",
      "886/886 - 1s - loss: 3.7179e-08 - accuracy: 1.0000 - 549ms/epoch - 619us/step\n",
      "Epoch 40/50\n",
      "886/886 - 1s - loss: 2.8564e-08 - accuracy: 1.0000 - 553ms/epoch - 624us/step\n",
      "Epoch 41/50\n",
      "886/886 - 1s - loss: 2.4310e-08 - accuracy: 1.0000 - 551ms/epoch - 622us/step\n",
      "Epoch 42/50\n",
      "886/886 - 1s - loss: 1.9653e-08 - accuracy: 1.0000 - 555ms/epoch - 626us/step\n",
      "Epoch 43/50\n",
      "886/886 - 1s - loss: 1.6934e-08 - accuracy: 1.0000 - 552ms/epoch - 623us/step\n",
      "Epoch 44/50\n",
      "886/886 - 1s - loss: 1.4942e-08 - accuracy: 1.0000 - 559ms/epoch - 631us/step\n",
      "Epoch 45/50\n",
      "886/886 - 1s - loss: 1.3730e-08 - accuracy: 1.0000 - 544ms/epoch - 614us/step\n",
      "Epoch 46/50\n",
      "886/886 - 1s - loss: 1.3030e-08 - accuracy: 1.0000 - 552ms/epoch - 623us/step\n",
      "Epoch 47/50\n",
      "886/886 - 1s - loss: 1.1711e-08 - accuracy: 1.0000 - 555ms/epoch - 626us/step\n",
      "Epoch 48/50\n",
      "886/886 - 1s - loss: 1.1146e-08 - accuracy: 1.0000 - 544ms/epoch - 614us/step\n",
      "Epoch 49/50\n",
      "886/886 - 1s - loss: 1.0957e-08 - accuracy: 1.0000 - 560ms/epoch - 632us/step\n",
      "Epoch 50/50\n",
      "886/886 - 1s - loss: 1.0903e-08 - accuracy: 1.0000 - 552ms/epoch - 623us/step\n",
      "99/99 - 0s - 85ms/epoch - 855us/step\n",
      "Epoch 1/50\n",
      "886/886 - 1s - loss: 2.5841 - accuracy: 0.4063 - 886ms/epoch - 1000us/step\n",
      "Epoch 2/50\n",
      "886/886 - 1s - loss: 0.6963 - accuracy: 0.9641 - 557ms/epoch - 629us/step\n",
      "Epoch 3/50\n",
      "886/886 - 1s - loss: 0.1660 - accuracy: 1.0000 - 549ms/epoch - 620us/step\n",
      "Epoch 4/50\n",
      "886/886 - 1s - loss: 0.0599 - accuracy: 1.0000 - 549ms/epoch - 620us/step\n",
      "Epoch 5/50\n",
      "886/886 - 1s - loss: 0.0281 - accuracy: 1.0000 - 556ms/epoch - 628us/step\n",
      "Epoch 6/50\n",
      "886/886 - 1s - loss: 0.0149 - accuracy: 1.0000 - 558ms/epoch - 629us/step\n",
      "Epoch 7/50\n",
      "886/886 - 1s - loss: 0.0086 - accuracy: 1.0000 - 558ms/epoch - 630us/step\n",
      "Epoch 8/50\n",
      "886/886 - 1s - loss: 0.0052 - accuracy: 1.0000 - 561ms/epoch - 633us/step\n",
      "Epoch 9/50\n",
      "886/886 - 1s - loss: 0.0032 - accuracy: 1.0000 - 552ms/epoch - 623us/step\n",
      "Epoch 10/50\n",
      "886/886 - 1s - loss: 0.0020 - accuracy: 1.0000 - 562ms/epoch - 634us/step\n",
      "Epoch 11/50\n",
      "886/886 - 1s - loss: 0.0013 - accuracy: 1.0000 - 564ms/epoch - 636us/step\n",
      "Epoch 12/50\n",
      "886/886 - 1s - loss: 8.3893e-04 - accuracy: 1.0000 - 556ms/epoch - 627us/step\n",
      "Epoch 13/50\n",
      "886/886 - 1s - loss: 5.5661e-04 - accuracy: 1.0000 - 558ms/epoch - 629us/step\n",
      "Epoch 14/50\n",
      "886/886 - 1s - loss: 3.5840e-04 - accuracy: 1.0000 - 560ms/epoch - 632us/step\n",
      "Epoch 15/50\n",
      "886/886 - 1s - loss: 2.4231e-04 - accuracy: 1.0000 - 566ms/epoch - 639us/step\n",
      "Epoch 16/50\n",
      "886/886 - 1s - loss: 1.5990e-04 - accuracy: 1.0000 - 555ms/epoch - 626us/step\n",
      "Epoch 17/50\n",
      "886/886 - 1s - loss: 1.0730e-04 - accuracy: 1.0000 - 563ms/epoch - 635us/step\n",
      "Epoch 18/50\n",
      "886/886 - 1s - loss: 7.3317e-05 - accuracy: 1.0000 - 568ms/epoch - 642us/step\n",
      "Epoch 19/50\n",
      "886/886 - 1s - loss: 4.8489e-05 - accuracy: 1.0000 - 565ms/epoch - 637us/step\n",
      "Epoch 20/50\n",
      "886/886 - 1s - loss: 3.2075e-05 - accuracy: 1.0000 - 562ms/epoch - 635us/step\n",
      "Epoch 21/50\n",
      "886/886 - 1s - loss: 2.1765e-05 - accuracy: 1.0000 - 564ms/epoch - 637us/step\n",
      "Epoch 22/50\n",
      "886/886 - 1s - loss: 1.4382e-05 - accuracy: 1.0000 - 595ms/epoch - 672us/step\n",
      "Epoch 23/50\n",
      "886/886 - 1s - loss: 9.7688e-06 - accuracy: 1.0000 - 571ms/epoch - 645us/step\n",
      "Epoch 24/50\n",
      "886/886 - 1s - loss: 6.6761e-06 - accuracy: 1.0000 - 607ms/epoch - 685us/step\n",
      "Epoch 25/50\n",
      "886/886 - 1s - loss: 4.3511e-06 - accuracy: 1.0000 - 571ms/epoch - 644us/step\n",
      "Epoch 26/50\n",
      "886/886 - 1s - loss: 2.9436e-06 - accuracy: 1.0000 - 589ms/epoch - 665us/step\n",
      "Epoch 27/50\n",
      "886/886 - 1s - loss: 1.8928e-06 - accuracy: 1.0000 - 582ms/epoch - 656us/step\n",
      "Epoch 28/50\n",
      "886/886 - 1s - loss: 1.3309e-06 - accuracy: 1.0000 - 561ms/epoch - 633us/step\n",
      "Epoch 29/50\n",
      "886/886 - 1s - loss: 9.1661e-07 - accuracy: 1.0000 - 582ms/epoch - 657us/step\n",
      "Epoch 30/50\n",
      "886/886 - 1s - loss: 6.2393e-07 - accuracy: 1.0000 - 555ms/epoch - 627us/step\n",
      "Epoch 31/50\n",
      "886/886 - 1s - loss: 4.2732e-07 - accuracy: 1.0000 - 562ms/epoch - 635us/step\n",
      "Epoch 32/50\n",
      "886/886 - 1s - loss: 2.9856e-07 - accuracy: 1.0000 - 575ms/epoch - 649us/step\n",
      "Epoch 33/50\n",
      "886/886 - 1s - loss: 2.1117e-07 - accuracy: 1.0000 - 559ms/epoch - 631us/step\n",
      "Epoch 34/50\n",
      "886/886 - 1s - loss: 1.4866e-07 - accuracy: 1.0000 - 590ms/epoch - 666us/step\n",
      "Epoch 35/50\n",
      "886/886 - 1s - loss: 1.1062e-07 - accuracy: 1.0000 - 591ms/epoch - 667us/step\n",
      "Epoch 36/50\n",
      "886/886 - 1s - loss: 7.9984e-08 - accuracy: 1.0000 - 615ms/epoch - 694us/step\n",
      "Epoch 37/50\n",
      "886/886 - 1s - loss: 6.2081e-08 - accuracy: 1.0000 - 619ms/epoch - 699us/step\n",
      "Epoch 38/50\n",
      "886/886 - 1s - loss: 4.6467e-08 - accuracy: 1.0000 - 576ms/epoch - 650us/step\n",
      "Epoch 39/50\n",
      "886/886 - 1s - loss: 3.5160e-08 - accuracy: 1.0000 - 571ms/epoch - 645us/step\n",
      "Epoch 40/50\n",
      "886/886 - 1s - loss: 2.7649e-08 - accuracy: 1.0000 - 627ms/epoch - 707us/step\n",
      "Epoch 41/50\n",
      "886/886 - 1s - loss: 2.2157e-08 - accuracy: 1.0000 - 623ms/epoch - 704us/step\n",
      "Epoch 42/50\n",
      "886/886 - 1s - loss: 1.7553e-08 - accuracy: 1.0000 - 665ms/epoch - 751us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "886/886 - 1s - loss: 1.4645e-08 - accuracy: 1.0000 - 600ms/epoch - 678us/step\n",
      "Epoch 44/50\n",
      "886/886 - 1s - loss: 1.2842e-08 - accuracy: 1.0000 - 631ms/epoch - 712us/step\n",
      "Epoch 45/50\n",
      "886/886 - 1s - loss: 1.1199e-08 - accuracy: 1.0000 - 629ms/epoch - 709us/step\n",
      "Epoch 46/50\n",
      "886/886 - 1s - loss: 1.0338e-08 - accuracy: 1.0000 - 607ms/epoch - 685us/step\n",
      "Epoch 47/50\n",
      "886/886 - 1s - loss: 9.0726e-09 - accuracy: 1.0000 - 565ms/epoch - 638us/step\n",
      "Epoch 48/50\n",
      "886/886 - 1s - loss: 8.6688e-09 - accuracy: 1.0000 - 564ms/epoch - 636us/step\n",
      "Epoch 49/50\n",
      "886/886 - 1s - loss: 8.9918e-09 - accuracy: 1.0000 - 580ms/epoch - 655us/step\n",
      "Epoch 50/50\n",
      "886/886 - 1s - loss: 8.5611e-09 - accuracy: 1.0000 - 570ms/epoch - 643us/step\n",
      "99/99 - 0s - 81ms/epoch - 815us/step\n",
      "Epoch 1/50\n",
      "886/886 - 1s - loss: 2.6097 - accuracy: 0.4056 - 891ms/epoch - 1ms/step\n",
      "Epoch 2/50\n",
      "886/886 - 1s - loss: 0.7197 - accuracy: 0.9551 - 576ms/epoch - 650us/step\n",
      "Epoch 3/50\n",
      "886/886 - 1s - loss: 0.1846 - accuracy: 1.0000 - 571ms/epoch - 645us/step\n",
      "Epoch 4/50\n",
      "886/886 - 1s - loss: 0.0625 - accuracy: 1.0000 - 565ms/epoch - 638us/step\n",
      "Epoch 5/50\n",
      "886/886 - 1s - loss: 0.0282 - accuracy: 1.0000 - 571ms/epoch - 645us/step\n",
      "Epoch 6/50\n",
      "886/886 - 1s - loss: 0.0147 - accuracy: 1.0000 - 559ms/epoch - 631us/step\n",
      "Epoch 7/50\n",
      "886/886 - 1s - loss: 0.0082 - accuracy: 1.0000 - 568ms/epoch - 641us/step\n",
      "Epoch 8/50\n",
      "886/886 - 1s - loss: 0.0049 - accuracy: 1.0000 - 564ms/epoch - 637us/step\n",
      "Epoch 9/50\n",
      "886/886 - 1s - loss: 0.0030 - accuracy: 1.0000 - 566ms/epoch - 638us/step\n",
      "Epoch 10/50\n",
      "886/886 - 1s - loss: 0.0019 - accuracy: 1.0000 - 557ms/epoch - 628us/step\n",
      "Epoch 11/50\n",
      "886/886 - 1s - loss: 0.0012 - accuracy: 1.0000 - 554ms/epoch - 625us/step\n",
      "Epoch 12/50\n",
      "886/886 - 1s - loss: 7.5852e-04 - accuracy: 1.0000 - 564ms/epoch - 636us/step\n",
      "Epoch 13/50\n",
      "886/886 - 1s - loss: 4.9087e-04 - accuracy: 1.0000 - 554ms/epoch - 626us/step\n",
      "Epoch 14/50\n",
      "886/886 - 1s - loss: 3.1884e-04 - accuracy: 1.0000 - 554ms/epoch - 625us/step\n",
      "Epoch 15/50\n",
      "886/886 - 1s - loss: 2.0638e-04 - accuracy: 1.0000 - 564ms/epoch - 636us/step\n",
      "Epoch 16/50\n",
      "886/886 - 1s - loss: 1.3652e-04 - accuracy: 1.0000 - 555ms/epoch - 626us/step\n",
      "Epoch 17/50\n",
      "886/886 - 1s - loss: 9.3445e-05 - accuracy: 1.0000 - 565ms/epoch - 637us/step\n",
      "Epoch 18/50\n",
      "886/886 - 1s - loss: 6.2440e-05 - accuracy: 1.0000 - 558ms/epoch - 630us/step\n",
      "Epoch 19/50\n",
      "886/886 - 1s - loss: 4.1981e-05 - accuracy: 1.0000 - 562ms/epoch - 634us/step\n",
      "Epoch 20/50\n",
      "886/886 - 1s - loss: 2.7270e-05 - accuracy: 1.0000 - 557ms/epoch - 629us/step\n",
      "Epoch 21/50\n",
      "886/886 - 1s - loss: 1.8461e-05 - accuracy: 1.0000 - 583ms/epoch - 658us/step\n",
      "Epoch 22/50\n",
      "886/886 - 1s - loss: 1.2009e-05 - accuracy: 1.0000 - 556ms/epoch - 627us/step\n",
      "Epoch 23/50\n",
      "886/886 - 1s - loss: 8.5261e-06 - accuracy: 1.0000 - 562ms/epoch - 635us/step\n",
      "Epoch 24/50\n",
      "886/886 - 1s - loss: 5.7309e-06 - accuracy: 1.0000 - 561ms/epoch - 633us/step\n",
      "Epoch 25/50\n",
      "886/886 - 1s - loss: 3.8916e-06 - accuracy: 1.0000 - 560ms/epoch - 632us/step\n",
      "Epoch 26/50\n",
      "886/886 - 1s - loss: 2.6707e-06 - accuracy: 1.0000 - 552ms/epoch - 623us/step\n",
      "Epoch 27/50\n",
      "886/886 - 1s - loss: 1.7145e-06 - accuracy: 1.0000 - 562ms/epoch - 634us/step\n",
      "Epoch 28/50\n",
      "886/886 - 1s - loss: 1.2068e-06 - accuracy: 1.0000 - 567ms/epoch - 640us/step\n",
      "Epoch 29/50\n",
      "886/886 - 1s - loss: 8.3498e-07 - accuracy: 1.0000 - 554ms/epoch - 625us/step\n",
      "Epoch 30/50\n",
      "886/886 - 1s - loss: 5.8575e-07 - accuracy: 1.0000 - 569ms/epoch - 642us/step\n",
      "Epoch 31/50\n",
      "886/886 - 1s - loss: 3.9120e-07 - accuracy: 1.0000 - 571ms/epoch - 644us/step\n",
      "Epoch 32/50\n",
      "886/886 - 1s - loss: 2.8453e-07 - accuracy: 1.0000 - 556ms/epoch - 627us/step\n",
      "Epoch 33/50\n",
      "886/886 - 1s - loss: 1.9610e-07 - accuracy: 1.0000 - 573ms/epoch - 647us/step\n",
      "Epoch 34/50\n",
      "886/886 - 1s - loss: 1.4869e-07 - accuracy: 1.0000 - 566ms/epoch - 639us/step\n",
      "Epoch 35/50\n",
      "886/886 - 1s - loss: 1.0368e-07 - accuracy: 1.0000 - 562ms/epoch - 635us/step\n",
      "Epoch 36/50\n",
      "886/886 - 1s - loss: 7.5165e-08 - accuracy: 1.0000 - 553ms/epoch - 624us/step\n",
      "Epoch 37/50\n",
      "886/886 - 1s - loss: 6.2539e-08 - accuracy: 1.0000 - 554ms/epoch - 625us/step\n",
      "Epoch 38/50\n",
      "886/886 - 1s - loss: 4.6225e-08 - accuracy: 1.0000 - 555ms/epoch - 626us/step\n",
      "Epoch 39/50\n",
      "886/886 - 1s - loss: 3.4864e-08 - accuracy: 1.0000 - 561ms/epoch - 633us/step\n",
      "Epoch 40/50\n",
      "886/886 - 1s - loss: 2.9291e-08 - accuracy: 1.0000 - 550ms/epoch - 621us/step\n",
      "Epoch 41/50\n",
      "886/886 - 1s - loss: 2.3153e-08 - accuracy: 1.0000 - 572ms/epoch - 645us/step\n",
      "Epoch 42/50\n",
      "886/886 - 1s - loss: 1.8307e-08 - accuracy: 1.0000 - 584ms/epoch - 659us/step\n",
      "Epoch 43/50\n",
      "886/886 - 1s - loss: 1.7015e-08 - accuracy: 1.0000 - 591ms/epoch - 667us/step\n",
      "Epoch 44/50\n",
      "886/886 - 1s - loss: 1.3945e-08 - accuracy: 1.0000 - 580ms/epoch - 654us/step\n",
      "Epoch 45/50\n",
      "886/886 - 1s - loss: 1.2438e-08 - accuracy: 1.0000 - 555ms/epoch - 626us/step\n",
      "Epoch 46/50\n",
      "886/886 - 1s - loss: 1.1442e-08 - accuracy: 1.0000 - 549ms/epoch - 619us/step\n",
      "Epoch 47/50\n",
      "886/886 - 1s - loss: 1.0015e-08 - accuracy: 1.0000 - 565ms/epoch - 637us/step\n",
      "Epoch 48/50\n",
      "886/886 - 1s - loss: 9.3688e-09 - accuracy: 1.0000 - 562ms/epoch - 635us/step\n",
      "Epoch 49/50\n",
      "886/886 - 1s - loss: 9.0726e-09 - accuracy: 1.0000 - 555ms/epoch - 626us/step\n",
      "Epoch 50/50\n",
      "886/886 - 1s - loss: 8.6419e-09 - accuracy: 1.0000 - 554ms/epoch - 625us/step\n",
      "99/99 - 0s - 88ms/epoch - 889us/step\n",
      "Epoch 1/50\n",
      "886/886 - 1s - loss: 2.4686 - accuracy: 0.4831 - 888ms/epoch - 1ms/step\n",
      "Epoch 2/50\n",
      "886/886 - 1s - loss: 0.5874 - accuracy: 0.9677 - 552ms/epoch - 623us/step\n",
      "Epoch 3/50\n",
      "886/886 - 1s - loss: 0.1427 - accuracy: 1.0000 - 554ms/epoch - 625us/step\n",
      "Epoch 4/50\n",
      "886/886 - 1s - loss: 0.0506 - accuracy: 1.0000 - 557ms/epoch - 628us/step\n",
      "Epoch 5/50\n",
      "886/886 - 1s - loss: 0.0236 - accuracy: 1.0000 - 574ms/epoch - 648us/step\n",
      "Epoch 6/50\n",
      "886/886 - 1s - loss: 0.0125 - accuracy: 1.0000 - 563ms/epoch - 635us/step\n",
      "Epoch 7/50\n",
      "886/886 - 1s - loss: 0.0072 - accuracy: 1.0000 - 561ms/epoch - 633us/step\n",
      "Epoch 8/50\n",
      "886/886 - 1s - loss: 0.0043 - accuracy: 1.0000 - 560ms/epoch - 632us/step\n",
      "Epoch 9/50\n",
      "886/886 - 1s - loss: 0.0026 - accuracy: 1.0000 - 560ms/epoch - 632us/step\n",
      "Epoch 10/50\n",
      "886/886 - 1s - loss: 0.0017 - accuracy: 1.0000 - 560ms/epoch - 632us/step\n",
      "Epoch 11/50\n",
      "886/886 - 1s - loss: 0.0011 - accuracy: 1.0000 - 547ms/epoch - 617us/step\n",
      "Epoch 12/50\n",
      "886/886 - 1s - loss: 6.8641e-04 - accuracy: 1.0000 - 576ms/epoch - 650us/step\n",
      "Epoch 13/50\n",
      "886/886 - 1s - loss: 4.4397e-04 - accuracy: 1.0000 - 551ms/epoch - 622us/step\n",
      "Epoch 14/50\n",
      "886/886 - 1s - loss: 2.9144e-04 - accuracy: 1.0000 - 568ms/epoch - 641us/step\n",
      "Epoch 15/50\n",
      "886/886 - 1s - loss: 1.8954e-04 - accuracy: 1.0000 - 562ms/epoch - 635us/step\n",
      "Epoch 16/50\n",
      "886/886 - 1s - loss: 1.2408e-04 - accuracy: 1.0000 - 556ms/epoch - 628us/step\n",
      "Epoch 17/50\n",
      "886/886 - 1s - loss: 8.1487e-05 - accuracy: 1.0000 - 583ms/epoch - 658us/step\n",
      "Epoch 18/50\n",
      "886/886 - 1s - loss: 5.3998e-05 - accuracy: 1.0000 - 594ms/epoch - 671us/step\n",
      "Epoch 19/50\n",
      "886/886 - 1s - loss: 3.5371e-05 - accuracy: 1.0000 - 567ms/epoch - 640us/step\n",
      "Epoch 20/50\n",
      "886/886 - 1s - loss: 2.3499e-05 - accuracy: 1.0000 - 568ms/epoch - 642us/step\n",
      "Epoch 21/50\n",
      "886/886 - 1s - loss: 1.5705e-05 - accuracy: 1.0000 - 572ms/epoch - 645us/step\n",
      "Epoch 22/50\n",
      "886/886 - 1s - loss: 1.0350e-05 - accuracy: 1.0000 - 561ms/epoch - 634us/step\n",
      "Epoch 23/50\n",
      "886/886 - 1s - loss: 6.8579e-06 - accuracy: 1.0000 - 550ms/epoch - 621us/step\n",
      "Epoch 24/50\n",
      "886/886 - 1s - loss: 4.5301e-06 - accuracy: 1.0000 - 566ms/epoch - 639us/step\n",
      "Epoch 25/50\n",
      "886/886 - 1s - loss: 3.1041e-06 - accuracy: 1.0000 - 561ms/epoch - 633us/step\n",
      "Epoch 26/50\n",
      "886/886 - 1s - loss: 2.0157e-06 - accuracy: 1.0000 - 565ms/epoch - 638us/step\n",
      "Epoch 27/50\n",
      "886/886 - 1s - loss: 1.3733e-06 - accuracy: 1.0000 - 578ms/epoch - 652us/step\n",
      "Epoch 28/50\n",
      "886/886 - 1s - loss: 9.2291e-07 - accuracy: 1.0000 - 576ms/epoch - 650us/step\n",
      "Epoch 29/50\n",
      "886/886 - 1s - loss: 6.3734e-07 - accuracy: 1.0000 - 562ms/epoch - 634us/step\n",
      "Epoch 30/50\n",
      "886/886 - 1s - loss: 4.2851e-07 - accuracy: 1.0000 - 578ms/epoch - 652us/step\n",
      "Epoch 31/50\n",
      "886/886 - 1s - loss: 2.9670e-07 - accuracy: 1.0000 - 560ms/epoch - 632us/step\n",
      "Epoch 32/50\n",
      "886/886 - 1s - loss: 2.1082e-07 - accuracy: 1.0000 - 578ms/epoch - 652us/step\n",
      "Epoch 33/50\n",
      "886/886 - 1s - loss: 1.4810e-07 - accuracy: 1.0000 - 573ms/epoch - 647us/step\n",
      "Epoch 34/50\n",
      "886/886 - 1s - loss: 1.1191e-07 - accuracy: 1.0000 - 560ms/epoch - 632us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "886/886 - 1s - loss: 7.9177e-08 - accuracy: 1.0000 - 568ms/epoch - 641us/step\n",
      "Epoch 36/50\n",
      "886/886 - 1s - loss: 5.9201e-08 - accuracy: 1.0000 - 564ms/epoch - 637us/step\n",
      "Epoch 37/50\n",
      "886/886 - 1s - loss: 4.4663e-08 - accuracy: 1.0000 - 558ms/epoch - 629us/step\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m estimator \u001b[38;5;241m=\u001b[39m KerasClassifier(model\u001b[38;5;241m=\u001b[39mbaseline_model, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     13\u001b[0m kfold \u001b[38;5;241m=\u001b[39m KFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 14\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkfold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean() * 100, results.std() * 100))\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\medicalMP\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\medicalMP\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\medicalMP\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\medicalMP\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\medicalMP\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\medicalMP\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\medicalMP\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\medicalMP\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\medicalMP\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\medicalMP\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\medicalMP\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\medicalMP\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\medicalMP\\lib\\site-packages\\scikeras\\wrappers.py:1494\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[1;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m   1492\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight\n\u001b[0;32m   1493\u001b[0m     sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, y\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m-> 1494\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1495\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\medicalMP\\lib\\site-packages\\scikeras\\wrappers.py:762\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[1;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    757\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit__epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs)\n\u001b[0;32m    759\u001b[0m )\n\u001b[0;32m    760\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 762\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    763\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    764\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    765\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    766\u001b[0m     warm_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarm_start,\n\u001b[0;32m    767\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    768\u001b[0m )\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\medicalMP\\lib\\site-packages\\scikeras\\wrappers.py:931\u001b[0m, in \u001b[0;36mBaseWrapper._fit\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    927\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_encoder_\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_model_compatibility(y)\n\u001b[1;32m--> 931\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_keras_model(\n\u001b[0;32m    932\u001b[0m     X,\n\u001b[0;32m    933\u001b[0m     y,\n\u001b[0;32m    934\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    935\u001b[0m     warm_start\u001b[38;5;241m=\u001b[39mwarm_start,\n\u001b[0;32m    936\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[0;32m    937\u001b[0m     initial_epoch\u001b[38;5;241m=\u001b[39minitial_epoch,\n\u001b[0;32m    938\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    939\u001b[0m )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\medicalMP\\lib\\site-packages\\scikeras\\wrappers.py:526\u001b[0m, in \u001b[0;36mBaseWrapper._fit_keras_model\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    524\u001b[0m         hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_args)\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 526\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_args)\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m warm_start \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m initial_epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory_ \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\medicalMP\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\medicalMP\\lib\\site-packages\\keras\\engine\\training.py:1641\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1639\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[0;32m   1640\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m-> 1641\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   1642\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m             epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m             _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m         ):\n\u001b[0;32m   1649\u001b[0m             callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\medicalMP\\lib\\site-packages\\keras\\engine\\data_adapter.py:1371\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[0;32m   1370\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1371\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1372\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1373\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1374\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m original_spe\n\u001b[0;32m   1376\u001b[0m )\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\medicalMP\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:639\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    638\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    640\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    641\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\medicalMP\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:727\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;124;03m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[0;32m    719\u001b[0m \n\u001b[0;32m    720\u001b[0m \u001b[38;5;124;03mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;124;03m  The value of the variable.\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 727\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_variable_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;66;03m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39midentity(value)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\medicalMP\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:706\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    704\u001b[0m       result \u001b[38;5;241m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mread_and_set_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mno_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    709\u001b[0m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[0;32m    710\u001b[0m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[0;32m    711\u001b[0m   tape\u001b[38;5;241m.\u001b[39mrecord_operation(\n\u001b[0;32m    712\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle],\n\u001b[0;32m    713\u001b[0m       backward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[0;32m    714\u001b[0m       forward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\medicalMP\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:696\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_copy \u001b[38;5;129;01mand\u001b[39;00m forward_compat\u001b[38;5;241m.\u001b[39mforward_compatible(\u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m    695\u001b[0m   gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mdisable_copy_on_read(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m--> 696\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_resource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_variable_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    698\u001b[0m _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, result)\n\u001b[0;32m    699\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\medicalMP\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:580\u001b[0m, in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m    579\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 580\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    581\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReadVariableOp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    583\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define baseline model\n",
    "    # create model\n",
    "model = Sequential()\n",
    "model.add(Dense(132, input_dim=132, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(41, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "estimator = KerasClassifier(model=baseline_model, epochs=50, batch_size=5, verbose=2)\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
    "# print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean() * 100, results.std() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186560c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7197b10b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medicalMP",
   "language": "python",
   "name": "medicalmp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
